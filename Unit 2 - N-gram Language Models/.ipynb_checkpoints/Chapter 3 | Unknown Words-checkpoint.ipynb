{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h4>Unit 2 <h1 style=\"text-align:center\"> Chapter 3</h1>\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last chapter we discussed about the problem of some words whose bigram probability is zero.\n",
    "\n",
    "In this chapter we will discuss about the problem of words that we have never seen in the training set but appear in test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Closed vocabulary\n",
    "\n",
    "> In a closed vocabulary system, it is guaranteed that the words will come from a list of defined words(wordlist). So there will be no unknown words in the test set.\n",
    "\n",
    "For example, in a machine translation task, the words will only come from a predefined pronounciation dictionary(There's only one correct pronounciation).\n",
    "\n",
    "As a result the language model, uses only these defined words from the predefined dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Open vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In an open vocabulary system, the vocabulary can have words that we have never seen before. These words are called <strong>unknown words</strong>, or <strong>out of vocabulary</strong> words.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out Of Vocabulary(OOV)\n",
    "\n",
    "> OOV words are the words that appear in test set but not in training set. The percentage of OOV words is called <strong>OOV rate</strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Open vocabulary system\n",
    "\n",
    "> In an open vocabulary system, we model the unknown words by adding a special word <UNK>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to solve the problem of OOV ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Transform the vocabulary to a closed vocabulary\n",
    "\n",
    "1. Use a fixed vocabulary.\n",
    "2. If the training set has a word that's not in the vocabulary, set it to the < UNK > token.\n",
    "3. Calculate the probabalilties normally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implicit vocabulary\n",
    "\n",
    "If a fixed vocabulary is not present, then create a vocabulary using the most frequent words, and marking everything else as < UNK >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Why should perplexity be compared across language models with same vocabulary?\n",
    "\n",
    "A language model can achieve low perplexity by choosing a small vocabulary and assigning the unknown word a high probability. For this reason, perplexities should only be compared across language models with the same vocabularies "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
