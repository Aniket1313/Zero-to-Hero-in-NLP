{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h4>Unit 2 <h1 style=\"text-align:center\"> Chapter 4</h1>\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words may be present in the vocabulary, but appear in the test set in an unknown context. In other words, some words appear in the test set after a word they never appeared after in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example,\n",
    "\n",
    "Suppose the training set has the following co-occurences as below:\n",
    "\n",
    "<strong>'I have taken the required steps'</strong><br>\n",
    "<strong>'The police officer took the required steps at the moment'</strong>\n",
    "\n",
    "Notice that in this little corpus, 'steps' come after 'required'.\n",
    "\n",
    "Now, in the test set, the sentence is,\n",
    "\n",
    "'The steps were mentioned clearly'\n",
    "\n",
    "### A n-gram language model will assign zero probability to this event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the language model from assigning zero probability to these events, we shave off some probability mass from freuqent events and give it to rare events.This is called <strong>smoothing</strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Smoothing / Discounting\n",
    "\n",
    "> Shave off probability mass from frequent events and pass it to rare events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Different ways of performing smoothing\n",
    "\n",
    "### Laplace Smoothing (add-1 smoothing)\n",
    "\n",
    "> Add 1 to all bigram counts before converting them to probabilities. This way, bigrams with count 0 will have count 1, bigrams with count 1 will have count 2 and henceforth.\n",
    "\n",
    "This algorithm is called <strong>Laplace Smoothing</strong> or <strong>add-one smoothing.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the unigram probability of a word $w_i$ is given by it's counts $c_i$ normalized by total number of word tokens $N$, given as:\n",
    "\n",
    "$P(w_i) = \\frac{c_i}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, Laplace smoothing adds 1 to the count, and since there are $V$ words in the vocabulary, and each word is incremented by 1, so the new equation looks like,\n",
    "\n",
    "$P_{laplace} (w_i) = \\frac{c_i + 1}{N+V}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define an adjusted count $c^*$ that defines how the smoothing algorithms affects the numerator.\n",
    "\n",
    "$c^*_i = (c_i + 1)\\frac{N}{N+V}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now turn $c_i^*$ into a probability by normalizing with $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discounting\n",
    "\n",
    "> Smoothing is discounting(bringing down) some non-zero counts to get the probability mass to pass onto zero counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$c_i^*$ is a discounted count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Add-k smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the same as add-1 smoothing but now instead of adding 1, we add a fractional count like (0.5, 0.01, etc).\n",
    "\n",
    "It usually does not work out well for language modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
