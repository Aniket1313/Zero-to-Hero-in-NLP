{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise | Building your own n-gram language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick recap to language models\n",
    "\n",
    "> Language models assign probability to predict the next word based on the previous words.\n",
    "\n",
    "1. n-gram language model - Predicts next word by looking at (n-1) words in the past.\n",
    "    - bi-gram/2-gram language model - Predicts next word by looking at (2-1) = 1 word in the past.\n",
    "    - tri-gram/3-gram language model - Predicts next word by looking at (3-1) = 2 words in the past.\n",
    "    \n",
    "    \n",
    "2. How to assign probabilites?\n",
    "\n",
    "Suppose the past words for a tri-gram language model are $w_1$, $w_2$ and we need to assign probability for the next word $w$.\n",
    "\n",
    "Count the number of times $w_1$ and $w_2$ come together[C1] , and count the number of times $w_1$, $w_2$, and $w$ come together [C2].\n",
    "\n",
    "Divide C2 by C1.\n",
    "\n",
    "$P(w | w_1,w_2) = \\frac{C2}{C1}$\n",
    "\n",
    "\n",
    "For example,\n",
    "\n",
    "Imagine you have a corpus, and you want to assign probability to the word 'Sam' after seeing two words 'I am'.\n",
    "\n",
    "Count the number of times 'I am Sam' come together, and count the number of times 'I am' come together. You will get the probability of getting 'Sam' after seeing 'I am'. Easy maths right?\n",
    "\n",
    "To generate more coherent sentence, we continue this simple math with chain rule of probability probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python code\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataset\n",
    "\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "# Import APIs for generating trigrams\n",
    "\n",
    "from nltk import trigrams\n",
    "\n",
    "# Import Counter API to store frequencies\n",
    "\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's name our State-Of-The-Art model as gptFree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x1a189227a0>, {})\n"
     ]
    }
   ],
   "source": [
    "gptFree = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# We don't want a KeyError, hence using defaultdict. \n",
    "# It will assign zero probability if a trigram probobality turns out zero\n",
    "\n",
    "print(gptFree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's count and store frequency of trigrams in the reuters data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in reuters.sents():\n",
    "    for word_1, word_2, word_3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "        gptFree[(word_1, word_2)][word_3] += 1 # Storing frequencies as and updating +1 as we see them\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert frequencies to probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word1_word2 in gptFree:\n",
    "    freq = float(sum(gptFree[word1_word2].values())) # Fetch frequencies of two words coming together\n",
    "    for word_3 in gptFree[word1_word2]:\n",
    "        gptFree[word1_word2][word_3] /= freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict next word\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Provide two starter words to predict the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obvious': 0.25, 'needed': 0.25, 'important': 0.25, 'happening': 0.25}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(gptFree['What','is'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'said': 0.34328358208955223,\n",
       " 'reiterated': 0.007462686567164179,\n",
       " 'holding': 0.014925373134328358,\n",
       " \"'\": 0.11194029850746269,\n",
       " 'stepped': 0.007462686567164179,\n",
       " 'is': 0.05223880597014925,\n",
       " 'expects': 0.007462686567164179,\n",
       " 'last': 0.007462686567164179,\n",
       " 'rate': 0.007462686567164179,\n",
       " 'dealers': 0.007462686567164179,\n",
       " 'also': 0.07462686567164178,\n",
       " ',': 0.05223880597014925,\n",
       " 'has': 0.04477611940298507,\n",
       " 'earlier': 0.022388059701492536,\n",
       " 'more': 0.007462686567164179,\n",
       " 'would': 0.007462686567164179,\n",
       " 'had': 0.014925373134328358,\n",
       " 'added': 0.007462686567164179,\n",
       " 'board': 0.014925373134328358,\n",
       " 'continued': 0.007462686567164179,\n",
       " 'previously': 0.007462686567164179,\n",
       " 'gave': 0.007462686567164179,\n",
       " 'moved': 0.007462686567164179,\n",
       " 'did': 0.007462686567164179,\n",
       " 'will': 0.04477611940298507,\n",
       " 'bought': 0.014925373134328358,\n",
       " 'estimated': 0.007462686567164179,\n",
       " 'was': 0.007462686567164179,\n",
       " 'transferred': 0.007462686567164179,\n",
       " 'official': 0.03731343283582089,\n",
       " 'of': 0.007462686567164179,\n",
       " 'rarely': 0.014925373134328358,\n",
       " 'forecasts': 0.007462686567164179}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(gptFree['The','bank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Generate a full sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have\n"
     ]
    }
   ],
   "source": [
    "text = list(map(str,input().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have spoken about the dollar up above 150 yen\n"
     ]
    }
   ],
   "source": [
    "# code courtesy of https://nlpforhackers.io/language-models/\n",
    "\n",
    "import random\n",
    "\n",
    "sentence_finished = False\n",
    " \n",
    "while not sentence_finished:\n",
    "  # select a random probability threshold  \n",
    "  r = random.random()\n",
    "  accumulator = .0\n",
    "\n",
    "  for word in gptFree[tuple(text[-2:])].keys():\n",
    "      accumulator += gptFree[tuple(text[-2:])][word]\n",
    "      # select words that are above the probability threshold\n",
    "      if accumulator >= r:\n",
    "          text.append(word)\n",
    "          break\n",
    "\n",
    "  if text[-2:] == [None, None]:\n",
    "      sentence_finished = True\n",
    " \n",
    "print (' '.join([t for t in text if t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
