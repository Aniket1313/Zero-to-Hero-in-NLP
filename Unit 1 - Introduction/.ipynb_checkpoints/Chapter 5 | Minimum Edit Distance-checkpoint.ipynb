{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h4>Unit 1 <h1 style=\"text-align:center\"> Chapter 5</h1>\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Coreference - The task of determining whether the two strings refer to the <strong>same entity</strong>.\n",
    "\n",
    "Example,\n",
    "\n",
    "- <strong>President of India, Mr. Narendra Modi</strong>\n",
    "- <strong>Indian President, Mr. Narendra Modi</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that two strings like the ones above, are very similary can be used as an evidence to decide if they coreferent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "But how do we quantify a string's similarity ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Edit Distance\n",
    "\n",
    "> Minimum edit distance is the minimum number of operations like insertion, deletion, substitution required to convert one string to another.\n",
    "\n",
    "Smaller the distance, more similar the strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at some examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Example 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose there are two strings,\n",
    "\n",
    "s1 = 'Woman'\n",
    "\n",
    "s2 = 'Women'\n",
    "\n",
    "The operations allowed are,\n",
    "\n",
    "```\n",
    "d - deletion\n",
    "s - substitution\n",
    "i - insertion\n",
    "```\n",
    "s1 can be converted to s2 just by a substituion operation - (s)\n",
    "\n",
    "Substitute <strong>e</strong> in s2 with an <strong>a</strong>.\n",
    "\n",
    "Now we can provide a weight to these 3 operations.\n",
    "If here the weight of each operation is 1, then the distance between s1 and s2 is 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein Distance\n",
    "\n",
    "> Levenshtein distance is a minimum distance metric in which each operation has a weight of 1, and substition is not allowed, which is equivalent of substitution having a weight of 2. (1 for insertion and 1 for deletion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Example 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take two strings,\n",
    "\n",
    "s1 = 'I N T E N T I O N'\n",
    "\n",
    "s2 = 'E X E C U T I O N'\n",
    "\n",
    "The operations allowed are,\n",
    "\n",
    "```\n",
    "d - deletion, weight = 1\n",
    "i - insertion, weight = 1\n",
    "\n",
    "```\n",
    "\n",
    "To convert s1 into s2, the following operations will be performed,\n",
    "\n",
    "- delete an 'I', cost = 1\n",
    "- substitute 'E' for 'N', cost = 2\n",
    "- substitute 'X' for 'T', cost = 2\n",
    "- insert 'C', cost = 1\n",
    "- substitute 'U' for 'N', cost = 2 \n",
    "\n",
    "Distance = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Edit Distance](../images/editDistance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Edit Distance Algorithm\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The minimum edit distance algorithm can be seen as finding the shortest path(minimum edits) from one string to another.\n",
    "\n",
    "This can be done using Dynammic Programming. Most of the NLP algorithms are based on Dynammic Programming.\n",
    "\n",
    "The intuition of Dynammic Programming is that a large problem can be solved by combining sub-problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python code for Minimum edit distance\n",
    "\n",
    "> It's okay if you don't understand the code, there's always a library for it. But try to make sense of the code. The concept should be clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\"\"\" Change the penalties here to deviate from the Levenshtein cost \"\"\"\n",
    "INSERTION_PENALTY = 1\n",
    "DELETION_PENALTY = 1\n",
    "SUBSTITUTION_PENALTY = 2\n",
    "ALLOWED_LEVELS = [\"word\", \"char\"]\n",
    "LEVEL = \"word\"\n",
    "\n",
    "\n",
    "reference = \"if there is no rain in April you will have a great summer\"\n",
    "sequences = [\"no rain in april then great summer come\",\n",
    "             \"there is rain in April you have summer\",\n",
    "             \"in April no rain you have summer great\",\n",
    "             \"there is no rain in apple a great summer comes\",\n",
    "             \"you have a great summer comes if there is no rain in April\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_cost(D, i, j, token_X, token_Y):\n",
    "    relative_subst_cost = 0 if token_X == token_Y else SUBSTITUTION_PENALTY\n",
    "    return min(D[i-1, j] + INSERTION_PENALTY, D[i, j-1] + DELETION_PENALTY, D[i-1, j-1] + relative_subst_cost)\n",
    "\n",
    "\n",
    "def tokenize_string(string, level=\"word\"):\n",
    "    assert level in ALLOWED_LEVELS\n",
    "    if level is \"word\":\n",
    "        return string.split(\" \")\n",
    "    else:\n",
    "        return list(string)\n",
    "\n",
    "\n",
    "def minimum_edit_distance(string1, string2, level=\"word\"):\n",
    "    \"\"\"The function uses the dynamic programming approach from Wagner-Fischer to compute the minimum edit distance\n",
    "    between two sequences.\n",
    "    :param string1 first sequence\n",
    "    :param string2 second sequence\n",
    "    :param level defines on which granularity the algorithm shall be applied. \"word\" specifies the token to\n",
    "    be sequential words while \"char\" applies the algorithm on a character-by-character level\"\"\"\n",
    "    string1_tokens = tokenize_string(string1, level)\n",
    "    string2_tokens = tokenize_string(string2, level)\n",
    "    n = len(string1_tokens)\n",
    "    m = len(string2_tokens)\n",
    "\n",
    "    print(string2_tokens)\n",
    "\n",
    "    D = np.zeros((n, m))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if j == 0:\n",
    "                D[i,j] = i\n",
    "            elif i == 0:\n",
    "                D[i,j] = j\n",
    "            else:\n",
    "                D[i,j] = compute_cost(D, i, j, string1_tokens[i], string2_tokens[j])\n",
    "\n",
    "    return D[n-1,m-1]\n",
    "\n",
    "\n",
    "def main():\n",
    "    for sequence in sequences:\n",
    "        print(minimum_edit_distance(reference, sequence, level=LEVEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'rain', 'in', 'april', 'then', 'great', 'summer', 'come']\n",
      "11.0\n",
      "['there', 'is', 'rain', 'in', 'April', 'you', 'have', 'summer']\n",
      "5.0\n",
      "['in', 'April', 'no', 'rain', 'you', 'have', 'summer', 'great']\n",
      "9.0\n",
      "['there', 'is', 'no', 'rain', 'in', 'apple', 'a', 'great', 'summer', 'comes']\n",
      "7.0\n",
      "['you', 'have', 'a', 'great', 'summer', 'comes', 'if', 'there', 'is', 'no', 'rain', 'in', 'April']\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
