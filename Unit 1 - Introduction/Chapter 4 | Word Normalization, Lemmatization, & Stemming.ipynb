{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h4>Unit 1 <h1 style=\"text-align:center\"> Chapter 4</h1>\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Normalization\n",
    "\n",
    "> Normalization is the task of putting words/tokens in a standard format.Normalization is benefecial despite the spelling information that is lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case folding\n",
    "---\n",
    "\n",
    "> Mapping everything to the same case is called case folding.\n",
    "\n",
    "Case folding is helpful for tasks like speech recognition, information retrieval.\n",
    "\n",
    "For sentiment analysis and other text classification tasks, information\n",
    "extraction, and machine translation, by contrast, case can be quite helpful and case\n",
    "folding is generally not done.\n",
    "\n",
    "\n",
    "Example,\n",
    "\n",
    "'US' the country and 'us' the pronoun can outweigh the advantage in\n",
    "generalization that case folding would have provided for other words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Case folding using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower case -> this string has a mix of lowercase and uppercase\n",
      "Upper case -> THIS STRING HAS A MIX OF LOWERCASE AND UPPERCASE\n",
      "Capitalized case -> This string has a mix of lowercase and uppercase\n",
      "Title case -> This String Has A Mix Of Lowercase And Uppercase\n",
      "Casefold ->  this string has a mix of lowercase and uppercase\n"
     ]
    }
   ],
   "source": [
    "sentence = 'THIS string Has a MIX of lowercase AND UPPERCASE'\n",
    "\n",
    "# Case folding to lowercase\n",
    "\n",
    "print(\"Lower case ->\", sentence.lower())\n",
    "\n",
    "# Case folding to UPPERCASE\n",
    "\n",
    "print(\"Upper case ->\", sentence.upper())\n",
    "\n",
    "# Case folding to first letter of first word in uppercase\n",
    "\n",
    "print(\"Capitalized case ->\", sentence.capitalize())\n",
    "\n",
    "# Case folding to title case\n",
    "\n",
    "print(\"Title case ->\", sentence.title())\n",
    "\n",
    "# More aggressive lower()\n",
    "\n",
    "print(\"Casefold -> \", sentence.casefold())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "---\n",
    "\n",
    "> Lemmatization is the task of determinig that the two words have the same root despite their surface differences.\n",
    "\n",
    "\n",
    "Example,\n",
    "\n",
    "Dinner & Dinners have the same <strong>lemma</strong> - Dinner\n",
    "\n",
    "<strong>Why is lemmatization done?</strong>\n",
    "\n",
    "There can be many reasons. One of the reasons is to reduce the vocabulary so that it does not have multiple words with exact same meaning.\n",
    "\n",
    "<strong>How is lemmatization done?</strong>\n",
    "\n",
    "Lemmatization method involves morphological parsing of the words.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morphology\n",
    "\n",
    "> Morphology is the study of how the words are built from smaller bearing units called <strong>morphemes</strong>.\n",
    "\n",
    "There are two main classes of morphemes,\n",
    "\n",
    "- <strong>Stem</strong> - The central morpheme of a word acting as the main.\n",
    "- <strong>Affixes</strong> - The additional part that gives the word a variation.\n",
    "\n",
    "For example,\n",
    "\n",
    "Suppose the word is <strong>Dinners</strong>, here,\n",
    "\n",
    "<strong>Stem</strong> = Dinner\n",
    "\n",
    "<strong>Affix</strong> = -s\n",
    "\n",
    "---\n",
    "\n",
    "> Lemmatization algorithms can be complex in nature. Hence, sometimes stemming is used for naive morphological analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "\n",
    "> Stemming is a naive version of morphological analysis in which consists of removing word affixes to normalize the word.\n",
    "\n",
    "The most commonly used stemming algorithm is <strong>The Porter Stemmer</strong> in which the text is run through a series of steps as a <strong>cascade</strong> in which the output of a pass is passed as input to the next.\n",
    "\n",
    "Stemming is essentially a way of normalizing text through a series of rules, hence there are some errors of under and over generalization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization and Stemming using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am going to the market to get some groceries\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "#nltk.download('all')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(lemmatizer.lemmatize('I am going to the market to get some groceries'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am going to the market to get some groceri\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "   \n",
    "ps = PorterStemmer() \n",
    "  \n",
    "print(ps.stem(\"I am going to the market to get some groceries\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sentence segmentation\n",
    "\n",
    "> Sentence segmentation is the task of dividing text into sentences. This can be done by taking help from punctuations like ., , !,?\n",
    "\n",
    "But this method can be confusing when the text has abbreviations like Mr., Miss., Inc. etc.\n",
    "There are other better methods for segmenting text into sentences.\n",
    "\n",
    "We will be discussing smarter methods in later notebooks. Let's look at a few naive approaches for sentence segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### Sentence segmentation using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = 'How was your day? Were you able to get stuff done? I\\'ll be taking a leave tommorow. \\\n",
    "Hope it\\'s okay.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['How was your day', ' Were you able to get stuff done', \" I'll be taking a leave tommorow\", \" Hope it's okay\", '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "segments_1 = re.split('[?,.]',sentence_1)\n",
    "print(len(segments_1))\n",
    "print(segments_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['Hello Mr', ' Brown', ' How was your day today', '']\n"
     ]
    }
   ],
   "source": [
    "sentence_2 = 'Hello Mr. Brown. How was your day today?'\n",
    "segments_2 = re.split('[?,.]',sentence_2)\n",
    "print(len(segments_2))\n",
    "print(segments_2)\n",
    "# Notice how this breaks Mr. and Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Another heuristic approach for sentence segmentation is to use a dictionary having common abbreviations, and then perform dictionary matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
